<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Migrate | Oh The Huge Manatee]]></title>
  <link href="http://ohthehugemanatee.github.io/blog/categories/migrate/atom.xml" rel="self"/>
  <link href="http://ohthehugemanatee.github.io/"/>
  <updated>2017-07-29T16:58:17+02:00</updated>
  <id>http://ohthehugemanatee.github.io/</id>
  <author>
    <name><![CDATA[Campbell Vertesi (ohthehugemanatee)]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Stop Waiting for Feeds Module: How to Import RSS in Drupal 8]]></title>
    <link href="http://ohthehugemanatee.github.io/blog/2017/06/07/stop-waiting-for-feeds-module-how-to-import-remote-feeds-in-drupal-8/"/>
    <updated>2017-06-07T06:33:24+02:00</updated>
    <id>http://ohthehugemanatee.github.io/blog/2017/06/07/stop-waiting-for-feeds-module-how-to-import-remote-feeds-in-drupal-8</id>
    <content type="html"><![CDATA[<p>How do you import an RSS feed into entities with Drupal 8? In Drupal 6 and 7, you probably used the <a href="https://drupal.org/project/feeds">Feeds</a> module. Feeds 7 made it easy (-ish) to click together a configuration that matches an RSS (or any XML, or CSV, or OPML, etc) source to a Drupal entity type, maps source data into Drupal fields, and runs an import with the site Cron. Where has that functionality gone in D8? I recently had to build a podcast mirror for a client that needed this functionality, and I was surprised at what I found.</p>

<p><strong>Feeds module</strong> doesn&rsquo;t have a stable release candidate, and it doesn&rsquo;t look like one is coming any time soon. They&rsquo;re still surveying people about what feeds module should even DO in D8. As the module page explains:</p>

<p><blockquote><p>It&rsquo;s not ready yet, but we are brainstorming about what would be the best way forward. Want to help us? Fill in our survey.<br/>If you decide to use it, don&rsquo;t be mad if we break it later.</p></blockquote></p>

<p>This does not inspire confidence.</p>

<p>The next great candidate is <a href="https://www.drupal.org/docs/8/core/modules/aggregator/overview">Aggregator</a> module (in core). Unfortunately, Aggregator gives you no control over the kind of entity to create, let alone any kind of field mapping. It imports content into its own Aggregated Content entity, with everything in one field, and linking offsite. I suppose you could extend it to choose you own entity type, map fields etc, but that seems like a lot of work for such a simple feature.</p>

<p>Frustrating, right?</p>

<p><strong>What if I told you that Drupal 8 can do everything Feeds 7 can?</strong></p>

<p>What if I told you that it&rsquo;s even better: instead of clicking through endless menus and configuration links, waiting for things to load, missing problems, and banging your head against the mouse, you can set this up with one simple piece of text. You can copy and paste it directly from this blog post into Drupal&rsquo;s admin interface.</p>

<h2>What? How?</h2>

<p>Drupal 8 can do all the Feedsy stuff you like with <a href="https://www.drupal.org/docs/8/api/migrate-api/migrate-api-overview">Migrate</a> module. Migrate in D8 core already contains all the elements you need to build a regular importer of ANYTHING into D8. Add a couple of contrib modules to provide specific plugins for XML sources and convenience drush functions, and <em>baby you&rsquo;ve got a stew goin'!</em></p>

<p>Here&rsquo;s the short version Howto:</p>

<p><strong>1) Download and enable <a href="https://drupal.org/project/migrate_plus">migrate_plus</a> and <a href="https://drupal.org/project/migrate_tools">migrate_tools</a> modules.</strong> You should be doing this with composer, but I won&rsquo;t judge. Just get them into your codebase and enable them. Migrate Plus provides plugins for core Migrate, so you can parse remote XML, JSON, CSV, or even arbitrary spreadsheet data. Migrate Tools gives us drush commands for running migrations.</p>

<p><strong>2) Write your Migration configuration in text</strong>, and paste it into the configuration import admin page (<code>admin/config/development/configuration/single/import</code>), or import it another way. I&rsquo;ve included a starter YAML just below, you should be able to copypasta, change a few values, and be done in time for tea.</p>

<p><strong>3) Add a line to your system cron</strong> to run <code>drush migrate -y my_rss_importer</code> at whatever interval you like.</p>

<p>That&rsquo;s it. One YAML file, most of which is copypasta. One cronjob. All done!</p>

<p>Here&rsquo;s my RSS importer config for your copy and pasting pleasure. If you&rsquo;re already comfortable with migration YAMLs and XPaths, just add the names of your RSS fields as selectors in the source section, map them to drupal fields in the process section, and you&rsquo;re all done!</p>

<p>If you aren&rsquo;t familiar with this stuff yet, don&rsquo;t worry! We&rsquo;ll dissect this together, below.</p>

<p>``` yaml
id: my_rss_importer
label: &lsquo;Import my RSS feed&rsquo;
status: true</p>

<p>source:
  plugin: url
  data_fetcher_plugin: http
  urls: &lsquo;<a href="https://example.com/feed.rss">https://example.com/feed.rss</a>&rsquo;
  data_parser_plugin: simple_xml</p>

<p>  item_selector: /rss/channel/item
  fields:</p>

<pre><code>-
  name: guid
  label: GUID
  selector: guid
-
  name: title
  label: Title
  selector: title
-
  name: pub_date
  label: 'Publication date'
  selector: pubDate
-
  name: link
  label: 'Origin link'
  selector: link
-
  name: summary
  label: Summary
  selector: 'itunes:summary'
-
  name: image
  label: Image
  selector: 'itunes:image[''href'']'
</code></pre>

<p>  ids:</p>

<pre><code>guid:
  type: string
</code></pre>

<p>destination:
  plugin: &lsquo;entity:node&rsquo;</p>

<p>process:
  title: title
  field_remote_url: link
  body: summary
  created:</p>

<pre><code>plugin: format_date
from_format: 'D, d M Y H:i:s O'
to_format: 'U'
source: pub_date
</code></pre>

<p>  status:</p>

<pre><code>plugin: default_value
default_value: 1
</code></pre>

<p>  type:</p>

<pre><code>plugin: default_value
default_value: podcast_episode
</code></pre>

<p>```</p>

<p>Some of you can just stop here. If you&rsquo;re familiar with the format and the structures involved, this example is probably all you need to set up your easy RSS importer.</p>

<p>In the interest of good examples for Migrate module though, I&rsquo;m going to continue. Read on if you want to learn more about how this config works, and how you can use Migrate to do even more amazing things&hellip;</p>

<h2>Anatomy of a migration YAML</h2>

<p>Let&rsquo;s dive into that YAML a bit. Migrate is one of the most powerful components of Drupal 8 core, and this configuration is your gateway to it.</p>

<p>That YAML looks like a lot, but it&rsquo;s really just 4 sections. They can appear in any order, but we need all 4: General information, source, destination, and data processing. This isn&rsquo;t rocket science after all! Let&rsquo;s look at these sections one at a time.</p>

<p><strong>General information</strong></p>

<p><code>yaml
id: my_rss_importer
label: 'My RSS feed importer'
status: true
</code>
This is the basic stuff about the migration configuration. At a minimum it needs a unique machine-readable ID, a human-readable label, and <code>status: true</code> so it&rsquo;s enabled. There are other keys you can include here for fun extra features, like module dependencies, groupings (so you can run several imports together!), tags, and language. These are the critical ones, though.</p>

<p><strong>Source</strong></p>

<p>``` yaml
source:
  plugin: url
  data_fetcher_plugin: file
  urls: &lsquo;<a href="https://example.com/feed.rss">https://example.com/feed.rss</a>&rsquo;
  data_parser_plugin: simple_xml</p>

<p>  item_selector: /rss/channel/item
  fields:</p>

<pre><code>-
  name: guid
  label: GUID
  selector: guid
-
  name: title
  label: Item Title
  selector: title
-
  name: pub_date
  label: 'Publication date'
  selector: pubDate
-
  name: link
  label: 'Origin link'
  selector: link
-
  name: summary
  label: Summary
  selector: 'itunes:summary'
</code></pre>

<p>  ids:</p>

<pre><code>guid:
  type: string
</code></pre>

<p>```
This is the one that intimidates most people: it&rsquo;s where you describe the RSS source. Migrate module is even more flexible than Feeds was, so there&rsquo;s a lot to specify here&hellip; but it all makes sense if you take it in small pieces.</p>

<p>First: we want to use a remote file, so we&rsquo;ll use the Url plugin (there are others, but none that we care about right now). All the rest of the settings belong to the Url plugin, even though they aren&rsquo;t indented or anything.</p>

<p>There are two possibilities for Url&rsquo;s data_fetcher setting: file and http. <code>file</code> is for anything you could pass to PHP&rsquo;s <a href="https://secure.php.net/manual/en/function.file-get-contents.php">file_get_contents</a>, including remote URLs. There are some great performance tricks in there, so it&rsquo;s a good option for most use cases. We&rsquo;ll be using <code>file</code> for our example. <code>http</code> is specifically for remote files accessed over HTTP, and lets you use the full power of the HTTP spec to get your file. Think authentication headers, cache rules, etc.</p>

<p>Next we declare which plugin will read (parse) the data from that remote URL. We can read JSON, SOAP, arbitrary XML&hellip; in our use case this is an RSS feed, so we&rsquo;ll use one of the XML plugins. SimpleXML is just what it sounds like: a simple way to get data out of XML. In extreme use cases you might use XML instead, but I haven&rsquo;t encountered that yet (ever, anywhere, in any of my projects). TL;DR: SimpleXML is great. Use it.</p>

<p>Third, we have to tell the source where it can find the actual items to import. XML is freeform, so there&rsquo;s no way for Migrate to know where the future &ldquo;nodes&rdquo; are in the document. So you have to give it the XPath to the items. RSS feeds have a standardized path: <code>/rss/channel/item</code>.</p>

<p>Next we have to identify the &ldquo;fields&rdquo; in the source. You see, migrate module is built around the idea that you&rsquo;ll map source fields to destination fields. That&rsquo;s core to how it thinks about the whole process. Since XML (and by extension RSS) is an unstructured format &ndash; it doesn&rsquo;t think of itself as having &ldquo;fields&rdquo; at all. So we&rsquo;ll have to give our source plugin XPaths for the data we want out of the feed, assigning each path to a virtual &ldquo;field&rdquo;. These &ldquo;fake fields&rdquo; let Migrate treat this source just like any other.</p>

<p>If you haven&rsquo;t worked with XPaths before, the example YAML in this post gives you most of what you need to know. It&rsquo;s just a simple text system for specifying a tag within an unstructured XML document. Not too complicated when you get into it. You may want to <a href="https://duckduckgo.com/?q=xpath+basics">find a good tutorial</a> to learn some of the tricks.</p>

<p>Let&rsquo;s look at one of these &ldquo;fake fields&rdquo;:</p>

<p>``` yaml</p>

<pre><code>  name: summary
  label: Summary
  selector: 'itunes:summary'
</code></pre>

<p>```
<em>name</em> is how we&rsquo;ll address this field in the rest of the migration. It&rsquo;s the source &ldquo;field name&rdquo;. <em>label</em> is the human readable name for the field. <em>selector</em> is the XPath inside the item. Most items are flat &ndash; certainly in RSS &ndash; so it&rsquo;s basically just the tag that surrounds the data you want. There, was that so hard?</p>

<p>As a side note, you can see that my RSS feeds tend to be for iTunes. Sometimes the world eats an apple, sometimes an apple eats the world. Buy me a beer at Drupalcon and we can argue about standards.</p>

<p>Fifth and finally, we identify which &ldquo;field&rdquo; in the source contains a unique identifier. Migrate module keeps track of the association between the source and destination objects, so it can handle updates, rollbacks, and more. The example YAML relies on the very common (but technically optional) <code>&lt;guid&gt;</code> tag as a unique identifier.</p>

<p><strong>Destination</strong></p>

<p><code>yaml
destination:
  plugin: 'entity:node'
</code>
Yep, it&rsquo;s that simple. This is where you declare what Drupal entity type will receive the data. Actually, you could write any sort of destination plugin for this &ndash; if you want Drupal to migrate data into some crazy exotic system, you can do it! But in 99.9% of cases you&rsquo;re migrating into Drupal entities, so you&rsquo;ll want <code>entity:something</code> here. Don&rsquo;t worry about bundles (content types) here; that&rsquo;s something we take care of in field mapping.</p>

<p><strong>Process</strong></p>

<p>``` yaml
process:
  title: title
  field_remote_url: link
  body: summary
  created:</p>

<pre><code>plugin: format_date
from_format: 'D, d M Y H:i:s O'
to_format: 'U'
source: pub_date
</code></pre>

<p>  status:</p>

<pre><code>plugin: default_value
default_value: 1
</code></pre>

<p>  type:</p>

<pre><code>plugin: default_value
default_value: podcast_episode
</code></pre>

<p>```</p>

<p>This is where the action happens: the process section describes how destination fields should get their data from the source. It&rsquo;s the &ldquo;field mapping&rdquo;, and more. Each key is a destination field, each value describes where the data comes from.</p>

<p>If you don&rsquo;t want to migrate the whole field exactly as it&rsquo;s presented in the source, you can put individual fields through <a href="https://www.drupal.org/docs/8/api/migrate-api/migrate-process-plugins">Migrate plugins</a>. These plugins apply all sorts of changes to the source content, to get it into the shape Drupal needs for a field value. If you want to take a substring from the source, explode it into an array, extract one array value and make sure it&rsquo;s a valid Drupal machine name, you can do that here. I won&rsquo;t do it in my example because that sort of thing isn&rsquo;t common for RSS feeds, but it&rsquo;s definitely possible.</p>

<p>The examples of plugins that you see here are simple ones. <code>status</code> and <code>type</code> show you how to set a fixed field value. There are other ways, but the <code>default_value</code> plugin is the best way to keep your sanity.</p>

<p>The <code>created</code> field is a bit more interesting. The Drupal field is a unix timestamp of the time a node was authored. The source RSS uses a string time format, though. We&rsquo;ll use the <code>format_date</code> plugin to convert between the two. Neat, eh?</p>

<p>Don&rsquo;t forget to map values into Drupal&rsquo;s <code>status</code> and <code>type</code> fields! <code>type</code> is especially important: that&rsquo;s what determines the content type, and nodes can&rsquo;t be saved without it!</p>

<h2>That&rsquo;s it?</h2>

<p>Yes, that&rsquo;s it. You now have a migrator that pulls from any kind of remote source, and creates Drupal entities out of the items it finds. Your system cron entry makes sure this runs on a regular schedule, rather than overloading Drupal&rsquo;s cron.</p>

<p>More importantly, if you&rsquo;re this comfortable with Migrate module, you&rsquo;ve just gained a <em>lot</em> of new power. This is a framework for getting data from anywhere, to anywhere, with a lot of convenience functionality in between.</p>

<p>Happy feeding!</p>

<h2>Tips and tricks</h2>

<p>OK I lied, there is way more to say about Migrate. It&rsquo;s a wonderful, extensible framework, and that means there are lots of options for you. Here are some of the obstacles and solutions I&rsquo;ve found helpful.</p>

<p><strong>Importing files</strong></p>

<p>Did you notice that I didn&rsquo;t map the images into Drupal fields in my example? That&rsquo;s because it&rsquo;s a bit confusing. We actually have an image URL that we need to download, then we have to create a file entity based on the downloaded file, and then we add the File ID to the node&rsquo;s field as a value. That&rsquo;s more complicated than I wanted to get into in the general example.</p>

<p>To do this, we have to create a pipeline of plugins that will operate in sequence, to create the value we want to stick in our field_image.  It looks something like this:</p>

<p>``` yaml
  field_image:</p>

<pre><code>-
  plugin: download
  source:
    - image
    - constants/destination_uri
  rename: true
-
  plugin: entity_generate
</code></pre>

<p>```
Looking at that download plugin, <em>image</em> seems clear. That&rsquo;s the source URL we got out of the RSS feed. But what is <em>constants/destination_uri</em>, I hear you cry? I&rsquo;m glad you asked. It&rsquo;s a constant, which I added in the source section and didn&rsquo;t tell you about. You can add any arbitrary keys to the source section, and they&rsquo;ll be available like this in processing. It is good practice to lump all your constants together into one key, to keep the namespace clean. This is what it looks like:</p>

<p>``` yaml
source:
  &hellip; usual source stuff here &hellip;
  constants:</p>

<pre><code>destination_uri: 'public://my_rss_feed/post.jpg'
</code></pre>

<p>```</p>

<p>Before you ask, yes this is exactly the same as using the <code>default_value</code> plugin. Still, <code>default_value</code> is preferred for readability wherever possible. In this case it isn&rsquo;t really possible.</p>

<p>Also, note that the download plugin lets me set <code>rename: true</code>. This means that in case of a name conflict, a <em>0, </em>1, <em>2, </em>3 etc will be added to the end of the filename.</p>

<p>You can see the whole structure here, of one plugin passing its result to the next. You can chain unlimited plugins together this way&hellip;</p>

<p><strong>Multiple interrelated migrations</strong></p>

<p>One of the coolest tricks that Migrate can do is to manage interdependencies between migrations. Maybe you don&rsquo;t want those images just as File entities, you actually want them in Paragraphs, which should appear in the imported node. Easy-peasy.</p>

<p>First, you have to create a second migration for the Paragraph. Technically you should have a separate Migration YAML for each destination entity type. (yes, <code>entity_generate</code> is a dirty way to get around it, use it sparingly). So we create our second migration just for the paragraph, like this:</p>

<p>``` yaml
id: my_rss_images_importer
label: &lsquo;Import the images from my RSS feed&rsquo;
status: true</p>

<p>source:
  plugin: url
  data_fetcher_plugin: http
  urls: &lsquo;<a href="https://example.com/feed.rss">https://example.com/feed.rss</a>&rsquo;
  data_parser_plugin: simple_xml</p>

<p>  item_selector: /rss/channel/item
  fields:</p>

<pre><code>-
  name: guid
  label: GUID
  selector: guid
-
  name: image
  label: Image
  selector: 'itunes:image[''href'']'
</code></pre>

<p>  ids:</p>

<pre><code>guid:
  type: string
</code></pre>

<p>  constants:</p>

<pre><code>destination_uri: 'public://my_rss_feed/post.jpg'
</code></pre>

<p>destination:
  plugin: &lsquo;entity:paragraph&rsquo;</p>

<p>process:
  type:</p>

<pre><code>plugin: default_value
default_value: podcast_image
</code></pre>

<p>  field_image:</p>

<pre><code>-
  plugin: download
  source:
    - image
    - constants/destination_uri
  rename: true
-
  plugin: entity_generate
</code></pre>

<p>```</p>

<p>If you look at that closely, you&rsquo;ll see it&rsquo;s a simpler version of the node migration we did at first. I did the copy pasting myself! Here are the differences:</p>

<ul>
<li>Different ID and label (duh)</li>
<li>We only care about two &ldquo;fields&rdquo; on the source: GUID and the image URL.</li>
<li>The destination is a paragraph instead of a node.</li>
<li>We&rsquo;re doing the image trick I just mentioned.</li>
</ul>


<p>Now, in the node migration, we can add our paragraphs field to the &ldquo;process&rdquo; section like this:</p>

<p>``` yaml
  field_paragraphs:</p>

<pre><code>plugin: migration_lookup
migration: my_rss_images_importer
source: guid
</code></pre>

<p><code>``
We're using the</code>migration_lookup<code>plugin. This plugin takes the value of the field given in</code>source<code>, and looks it up in</code>my_rss_images_importer<code>to see if anything with that source ID was migrated. Remember where we configured the source plugin to know that</code>guid` was the unique identifier for each item in this feed? That comes in handy here.</p>

<p>So we pass the guid to <code>migration_lookup</code>, and it returns the id of the paragraph which was created for that guid. It finds out what Drupal entity ID corresponds to that source ID, and returns the Drupal entity ID to use as a field value. You can use this trick to associate content migrated from separate feeds, totally separate data sources, or whatever.</p>

<p>You should also add a dependency on <code>my_rss_images_importer</code> at the bottom of your YAML file, like this:</p>

<p>``` yaml
migration_dependencies:
  required:</p>

<pre><code>- my_rss_images_importer
</code></pre>

<p>```</p>

<p>This will ensure that <code>my_rss_images_importer</code> will always run before <code>my_rss_importer</code>.</p>

<p>(NB: in Drupal &lt; 8.3, this plugin is called <code>migration</code>)</p>

<p><strong>Formatting dates</strong></p>

<p>Very often you will receive dates in a format other than what Drupal wants to accept as a valid field value. In this case the <code>format_date</code> process plugin comes in very handy, like this:</p>

<p>```
  field_published_date:</p>

<pre><code>plugin: format_date
from_format: 'D, d M Y H:i:s O'
to_format: 'Y-m-d\TH:i:s'
source: pub_date
</code></pre>

<p>```</p>

<p>This one is pretty self-explanatory: from format, to format, and source. This is important when migrating from Drupal 6, whose date fields store dates differently from 8. It&rsquo;s also sometimes handy for RSS feeds. :)</p>

<p><strong>Drush commands</strong></p>

<p>Very important for testing, and the whole reason we have <code>migrate_plus</code> module installed! Here are some handy drush commands for interacting with your migration:</p>

<ul>
<li><code>drush ms</code>: Gives you the status of all known migrations. How many items are there to import? How many have been imported? Is the import running?</li>
<li><code>drush migrate-rollback</code>: Rolls back one or more migrations, deleting all the imported content.</li>
<li><code>drush migrate-messages</code>: Get logged messages for a particular migration.</li>
<li><code>drush mi</code>: Runs a migration. use <code>--all</code> to run them all. Don&rsquo;t worry, Migrate will sort out any dependencies you&rsquo;ve declared and run them in the right order. Also worth noting: <code>--limit=10</code> does a limited run of 10 items, and <code>--feedback=10</code> gives you an in-progress status line every 10 items (otherwise you get nothing until it&rsquo;s finished!).</li>
</ul>


<p>Okay, now that&rsquo;s really it. Happy feeding!</p>

<p><img class="center" src="/images/feed-me-seymour.gif" title="&ldquo;Feed me, Seymour!&rdquo;" ></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Between the Cracks of Decoupled (Drupal) Architecture]]></title>
    <link href="http://ohthehugemanatee.github.io/blog/2017/02/11/a-year-between-the-cracks-of-decoupled-drupal/"/>
    <updated>2017-02-11T11:18:44+01:00</updated>
    <id>http://ohthehugemanatee.github.io/blog/2017/02/11/a-year-between-the-cracks-of-decoupled-drupal</id>
    <content type="html"><![CDATA[<p>In any decoupled architecture, people tend to focus on the pieces that will fit together. But what nobody ever tells you is: <em>watch out for the cracks!</em></p>

<p>The cracks are the integration points between the different components. It&rsquo;s not GraphQL as a communication layer; it&rsquo;s that no one thinks to log GraphQL inconsistencies when they occur. It&rsquo;s not &ldquo;what&rsquo;s my development environment&rdquo;, it&rsquo;s &ldquo;how do these three development environments work on my localhost at the same time?&rdquo;. It&rsquo;s the thousand little complexities that you don&rsquo;t think about, basically because they aren&rsquo;t directly associated with a noun. We&rsquo;ve discovered &ldquo;crack&rdquo; problems like this in technical architecture and devops, communication, and even project management. They add up to a lot of unplanned time, and they have presented some serious project risks.</p>

<p>A bit more about my recent project with <a href="https://amazeelabs.com">Amazee Labs</a>. It&rsquo;s quite a cool stack: several data sources feed into <a href="https://drupal.org">Drupal 8</a>, which offers an editorial experience and <a href="https://graphql.org">GraphQL</a> endpoints. Four <a href="https://facebook.github.io/react/">React</a>/<a href="https://facebook.github.io/relay/">Relay</a> sites sit in front, consuming the data and even offering an authenticated user experience (<a href="https://auth0.com">Auth0</a>). I&rsquo;ve been working with brilliant people: <a href="https://www.drupal.org/u/fubhy">Sebastian Siemssen</a>, <a href="https://www.drupal.org/u/moshe-weitzman">Moshe Weitzman</a>, <a href="https://github.com/pmelab">Philipp Melab</a>, and others. It has taken all of us to deal with the crack complexity.</p>

<p>The first crack appeared as we were setting up environments for our development teams. How do you segment repositories? They get deployed to different servers, and run in very different environments. But they are critically connected to each other. We decided to have a separate &ldquo;back end&rdquo; repo, and separate repos for each &ldquo;front end&rdquo; site. Since Relay needs to compile the entire data schema on startup, this means that every time the back end is redeployed with a data model change, we have to automatically redeploy the front end(s). For local development, we ended up building a mock data backend in MongoDB running in Docker. Add one more technology to support to your list, with normal attendant support and maintenance issues.</p>

<p>DevOps in general is more complicated and expensive in a decoupled environment. It&rsquo;s all easy at first, but at some point you have to start connecting the front- and back-ends on peoples' local development environments. Cue obvious problems like port conflicts, but also less obvious ones. The React developers don&rsquo;t know anything about drupal, drush, or php development environments. This means your enviroment setup needs to be VERY streamlined, even idiot-proof. Your devops team has to support a much wider variety of users than normal. Two of our front-enders had setups that made spinning up the back-end take more than 30 minutes. 30 minutes! We didn&rsquo;t even know that was possible with our stack.  The project coordinater has to budget significant time for this kind of support and maintenance.</p>

<p>Some of the cracks just mean you have to code <em>very</em> carefully. At one point we discovered that certain kinds of invalid schema are perfectly tolerable to the GraphQL module. We could query everything just fine &ndash; but React couldn&rsquo;t compile the schema, and gave cryptic errors that were hard to track down. Or what about the issues where there <em>are</em> no error messages to work with? CORS problems were notoriously easy to miss, until everything broke without clear errors. Some of these are impossible to avoid. The best you can do is be thorough about your test coverage, add integration tests which consider all environments, and <em>document all the things</em>.</p>

<p>Not all the cracks are technological; some are purely communication. In order to use a shared data service, we need a shared data model and API. So how do you communicate and coordinate that between 5 teams and 5 applications? We found this bottleneck extremely difficult. At first, it simply took a long time to get API components built. We had to coordinate so many stakeholders, that the back-end data arch and GraphQL endpoints got way behind the front-end sites. At another point, one backender organically became the go-to for everything GraphQL. He was a bottleneck within weeks, and was stuck with all the information silo'ed in his head. This is still an active problem area for us. We&rsquo;re working on thorough and well-maintained documentation as a reference point, but this costs time as well.</p>

<p>Even project managers and scrum masters found new complexities. We had more than 30 people working on this project, and everyone had to be well coordinated and informed. You certainly can&rsquo;t do scrum with 30 people together &ndash; the sprint review would take days! But split it out into many smaller teams and your information and coordination problems just got much harder. Eventually we found our solution: we have 3 teams, each with their own PO, frontender(s) and backender(s), who take responsibility for whole features at a time. Each team does its own, quite vanilla, scrum process. Layered on top of this, developers are in groups which cut across the scrum teams, which have coordination meetings and maintain documentation and code standards. All the back-enders meet weekly and work with the same standards, but the tightest coordination is internal to a feature. So far this is working well, but ask me again in a few months. :)</p>

<p>Working in a fully decoupled architecture and team structure has been amazing. It really is possible, and it really does provide a lot more flexibility. But it demands a harder focus on standards, communication, coordination, and architecture. Sometimes it&rsquo;s not about the bricks; it&rsquo;s about the mortar between them. So the next time you start work on a decoupled architecture, <em>watch out for the cracks!</em></p>
]]></content>
  </entry>
  
</feed>
