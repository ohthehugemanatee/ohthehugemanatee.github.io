<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Aws | Oh, The Huge Manatee]]></title>
  <link href="http://ohthehugemanatee.org/blog/categories/aws/atom.xml" rel="self"/>
  <link href="http://ohthehugemanatee.org/"/>
  <updated>2019-02-11T13:53:38+01:00</updated>
  <id>http://ohthehugemanatee.org/</id>
  <author>
    <name><![CDATA[Campbell Vertesi (ohthehugemanatee)]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Simple AWS Backups With Snapshots and AMIs]]></title>
    <link href="http://ohthehugemanatee.org/2011/04/simple-aws-backups-with-snapshots-and.html"/>
    <updated>2011-04-30T15:26:00+02:00</updated>
    <id>http://ohthehugemanatee.org/2011/04/simple-aws-backups-with-snapshots-and</id>
    <content type="html"><![CDATA[<p></p>

<div class="css-full-post-content js-full-post-content">
Are you just getting started with Amazon Web Services? &nbsp;It's a great service, but it faces some reliability challenges. &nbsp;This post explains how to set up a simple backup system using Amazon's "snapshot" "machine image" functionalities.<br /><br /><b>Dependencies</b><br /><br />Before you begin, you will need:<br /><br /><ul><li>Amazon's standard <a href="http://aws.amazon.com/developertools/351?_encoding=UTF8&amp;jiveRedirect=1">EC2 Command Line Tools</a></li><li>Alestic's <a href="http://alestic.com/2009/09/ec2-consistent-snapshot">ebs-consistent-snapshot</a> program</li><li>Tech Kismet's <a href="http://remove-old-snapshots.php/">remove-old-snapshots.php</a> script (which must be so named)</li></ul><br /><div><br /></div><div><b>AMI Images</b></div><div><b><br /></b></div><div>Everyone knows that Amazon Instances are ephemeral. &nbsp;When you shut down your server, it's really gone. So the first thing you want to do is create an "Amazon Machine Image" of your server. &nbsp;You can use an AMI to start new instances anytime you like, and the backup is stored on S3 so it is region-independent. &nbsp;Anyone who felt the EBS regional downtime last week is looking for region-independent backup solutions.</div><div><br /></div><div>So here's a little script I wrote to do a regular backup of your server to AMI:</div><br /><blockquote><code><br />#!/bin/bash<br /># Variables.  Change this to suit the server.  Exceptions should be a comma-separated list of directories to exclude from the backup.&nbsp;</code>&nbsp;</blockquote><blockquote><code> SERVER="server-name" #the name of the server you are backing up&nbsp;</code><br /><div><code>UID="1234-1234-1234" # Your Amazon user ID number&nbsp;</code></div><div><code>CERT="/path/to/your/certfile.pem" # Your Amazon certificate file&nbsp;</code></div><div><code>KEY="/path/to/your/key.pem" #Your Amazon key file</code></div><div><code>ACCESSKEY="12345567823SSDFGS6" #your Amazon access key</code></div><div><code>SECRETKEY="aSDFOUxsfoiusfSDF12SF/Sfi0Asgoiwre" #your amazon secret key&nbsp;</code><br /><div><code>EXCEPTIONS="/ebs,/mnt" #Directories you want to exclude&nbsp;</code><br /><div><code>DESTINATION="/mnt" #Temporary filespace for building the backup itself&nbsp;</code></div><br /><div><code>ARCH="x86_64" # Is your Instance 32 or 64 bit? <br />DATE=`date +%Y-%m-%d` #today's date<br /><br /><br /># set up nice error handling function error_exit { echo "$1" 1&gt;&amp;2 exit 1 }<br />rm -rf "$DESTINATION"/backup* echo "$(date) Starting instance backup script." echo "creating backup bundle..."<br />if /usr/bin/ec2-bundle-vol -u $UID -c $CERT -k $KEY -p backup-$SERVER-$DATE -r $ARCH -e "$EXCEPTIONS" -d "$DESTINATION"; then   echo "SUCCESS" else    error_exit "ERROR creating bundle. Exiting..." fi echo "uploading backup bundle..."<br />if /usr/bin/ec2-upload-bundle -b backup  -m "$DESTINATION"/backup-$SERVER-$DATE.manifest.xml -a $ACCESSKEY -s $SECRETKEY; then    echo "SUCCESS" else   error_exit "ERROR uploading bundle.  Exiting..." fi<br />echo "registering backup bundle with AWS..."<br />if ec2-register -K $KEY -C $CERT backup/backup-$SERVER-$DATE.manifest.xml; then   echo "SUCCESS" else   error_exit "ERROR registering bundle.  Exiting..." fi<br />echo "deleting backup cache..."<br />if rm -rf "$DESTINATION"/backup*; then   echo "SUCCESS" else   error_exit "ERROR deleting backup cache.  Exiting..." fi<br />echo "backup commands run successfully"<br />exit 0<br /></code></div></div></div></blockquote><br />Run this guy on cron, and you have a regular backup going. &nbsp;The one thing it does not do is prune old backups. &nbsp;Most server setups are fire-and-forget - this is a way of documenting that firing process for next time.<br /><br /><b>EBS Snapshots</b><br /><b><br /></b><br />The counterpart to Instances are EBS data stores. &nbsp;These are block devices that provide permanent storage on Amazon's cloud. &nbsp;Here's my backup script for an attached EBS store.<br /><br /><code><br /></code><br /><blockquote><code> #!/bin/bash</code><code><br /></code><code> # Variables. &nbsp;Change this to suit the server. &nbsp;Mysql User needs access to lock and unlock tables. Number is how many old backup snapshots to keep.</code><code><br /></code><code> SERVER="server-name" #the name of the server you are backing up, for labeling</code><code> VOLUME="vol-1234567a" #the volume ID that you are backing up</code><code> MOUNTPOINT="/ebs" #where the volume is mounted</code><code> MYSQLUSER="root" #a mysql user with access to lock all tables</code><code> MYSQLPASS="password" #password for the mysql user</code><code> KEYID=12345799asf8675asf #your Amazon key</code><code> SECRETKEY=asf765sdg876wrkhalsfa/234@$ &nbsp;# your Amazon secret key</code><code> NUMBER="15" # How many old backups to keep</code><code> DATE=`date +%Y-%m-%d` #today's date</code><code><br /></code><code><br /></code><code> # set up nice error handling</code><code> function error_exit</code><code> {</code><code> &nbsp; &nbsp; &nbsp; &nbsp; echo "$1" 1&gt;&amp;2</code><code> &nbsp; &nbsp; &nbsp; &nbsp; exit 1</code><code> }</code><code><br /></code><code> echo "$(date) Starting EBS backup script."</code><code> echo "creating EBS snapshot..."</code><code><br /></code><code> if /usr/bin/ec2-consistent-snapshot --description "$SERVER backup $DATE" --aws-access-key-id $KEYID --aws-secret-access-key $SECRETKEY --mysql-username $MYSQLUSER --mysql-password $MYSQLPASS --xfs-filesystem "$MOUNTPOINT" $VOLUME;&nbsp;</code><span class="Apple-style-span" style="font-family: monospace;">then</span><code> &nbsp; echo "SUCCESS"</code><code> else</code><code> &nbsp; error_exit "ERROR creating snapshot. Exiting..."</code><code> &nbsp; exit 1</code><code> fi</code><code><br /></code><code> if /usr/bin/php /usr/sbin/remove-old-snapshots.php -v $VOLUME -n $NUMBER ; then</code><code> &nbsp; echo "SUCCESS"</code><code> else</code><code> &nbsp; error_exit "ERROR removing old snapshots. &nbsp;Exiting..."</code><code> &nbsp; exit 1</code><code> fi</code><code><br /></code><code> echo "backup commands run successfully"</code><code> exit 0</code></blockquote><br /><code></code><br /><div><br />This little guy is very useful if you have an EBS device that you use for a running MySQL instance. It will lock MySQL tables briefly, and start the snapshot process from Amazon. &nbsp;This one does prune old backups, you can specify how many you want to keep. <br /><br />The biggest down side to the EBS snapshot is that it is zone-locked. &nbsp;An EBS snapshot can only be used in the zone where it was created. &nbsp;So in the case of a zone-specific outage, you're SOL.<br /><br />This is not a proper, region-independent, auto-pruning, tested backup system. &nbsp;This is a set of basic element scripts that you can run on cron, and have some peace of mind while you look into something more robust. &nbsp; &nbsp;But it is a good start, at least!</div>
</div>


<p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS Load Balancer SSL Limitations]]></title>
    <link href="http://ohthehugemanatee.org/2011/04/aws-load-balancer-ssl-limitations.html"/>
    <updated>2011-04-29T13:58:00+02:00</updated>
    <id>http://ohthehugemanatee.org/2011/04/aws-load-balancer-ssl-limitations</id>
    <content type="html"><![CDATA[<p></p>

<div class="css-full-post-content js-full-post-content">
No one else seems to have documented this anywhere, so I'm gonna do it here.<br /><br />Amazon Web Services has a great little load balancer system you can use. &nbsp;A few clicks, and you're away to the races with a shiny load balancer of your own! &nbsp;The best part? &nbsp;It will even do SSL termination at the load balancer for you. &nbsp;Just paste in your certs and away you go! &nbsp;Right?<br /><br />Wrong. &nbsp;Seems like every time I do this, I end up with an invalid certificate at some stage of the game. Amazon doesn't tell you WHAT about your cert is wrong, or even what cert formats they want. &nbsp;They just say "error: invalid private key".<br /><br />I use a lot of Comodo certificates, which take about a day to generate. &nbsp;I don't know why it takes them that long, maybe they're lovingly hand crafted by artisanal SSL certificate islanders on a small pacific island. &nbsp;The point is, it takes for ever for them to respond to a request for a new cert, and that means I don't like to sit around regenerating certs in different formats at random until I figure out what Amazon wants.<br /><br />So here's what I worked out - you can do this at home yourself. &nbsp;I generated my private key and certificate request with the often used:<br /><blockquote>openssl req -new -nodes -keyout swearingatcomputers.key -out swearingatcomputers.csr</blockquote>This is the lazy man's approach. &nbsp;It doesn't bother me about a password for the key, I don't have to type two separate commands... I just get a nice quick key that I can use. &nbsp;Comodo accepts the key and certificate request, and 24 hours later my signed public certificate and authority chain file are delivered in the mail. &nbsp;When I set up SSL with Apache, this is fine.<br /><br />But try and drop this into Amazon, and you get one of those mysterious messages "error: invalid private key". &nbsp;Turns out your keys have to be RSA or DSA encrypted in order for Amazon to accept them. &nbsp;To see if you're affected, just look at the first line of your key file. &nbsp;If it says "BEGIN PRIVATE KEY", then read on. &nbsp;If it says "BEGIN RSA PRIVATE KEY" or "BEGIN DSA PRIVATE KEY", then this won't interest you , sorry.<br /><br />So to fix this problem, you SHOULD have used a slightly different command to generate that key:<br /><br /><blockquote>openssl req -nodes -newkey rsa:2048 -keyout swearingatcomputers.key -out swearingatcomputers.csr</blockquote>At this point, I started swearing at computers. &nbsp;I have to wait another 24 hours for some pacific islander to meticulously hand-paint <b>another</b>&nbsp;cert? &nbsp;Ridiculous!<div><br /></div><div>But don't you fret. &nbsp;You can actually convert the certs you have into RSA versions that Amazon will love. First, the private key:</div><blockquote>openssl rsa -in swearingatcomputers.key -text</blockquote>This will spit out all the calculations openssl has to do to read the key, and at the end - an RSA encrypted key! &nbsp;Just copy and paste the RSA PRIVATE KEY section at the end (including the BEGIN and END lines) into a separate file, or into AWS directly, and there ya go! &nbsp;<br /><br />In order to make the public certificate match, you'll have to convert that, too.<br /><br /><blockquote>openssl x509 -inform PEM -in swearingatcomputers.crt</blockquote><div>BAM - out comes your fancy key for Amazon usage.</div><div><br /></div><div>And that's it! &nbsp;I'm happy SOMEONE took the time to document Amazon's SSL key requirements. &nbsp;They make sense, they're smart requirements... but they have to be written somewhere for poor rubes like me.</div>
</div>


<p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Multiple SSL Sites on One AWS Instance]]></title>
    <link href="http://ohthehugemanatee.org/2011/04/multiple-ssl-sites-on-one-aws-instance.html"/>
    <updated>2011-04-29T13:44:00+02:00</updated>
    <id>http://ohthehugemanatee.org/2011/04/multiple-ssl-sites-on-one-aws-instance</id>
    <content type="html"><![CDATA[<p></p>

<div class="css-full-post-content js-full-post-content">
It's a familiar problem - you can't really host multiple SSL sites on a single IP address. &nbsp;There's a fancy workaround if you get a pricey multi-domain certificate, of course. &nbsp;But separate sites, with separate certificates just won't work. &nbsp;The reason is simple - put yourself in Apache's shoes.<br /><br />When you're using name based virtualhosts, Apache uses the request headers to determine which vhost should get the request. &nbsp;But HTTPS headers are encrypted! &nbsp;So there's no way for Apache to tell which virtual host should get this message, without decrypting it furst. &nbsp;But it can't decrypt without knowing the correct virtual host...<br /><br />There's a great workaround for this with Amazon, using their Elastic Load Balancer (ELB) system. &nbsp;You simply set up a load balancer, and forward port 443 to, say port 8443 on your instance, and have Apache listen on 8443 for SSL connections. &nbsp;Recently Amazon rolled out the ability to terminate SSL on the load balancer, so you can actually have the ELB listen on 443, decrypt the traffic with your certs, and forward the request to your Instance the clear, on port 80. <br /><br />There is one weakness. &nbsp;ELBs cannot be addressed by IP address. They can only be addressed by CNAME - and can anyone think of why this might cause problems? &nbsp;If you said "your root DNS record can't be a CNAME", go get yourself a glass of milk and some oreos, you've earned them. &nbsp;Now this is one of those DNS rules that is often ignored. &nbsp;For most people, having a CNAME for swearingatcomputers.com really isn't going to break anything. &nbsp;But for anyone who uses email on their domain, this is an important rule to follow. &nbsp;Your MX records require that there be an A record for the domain. <br /><br />Still, this will get you to a pretty good place. &nbsp;You can have https://secure.swearingatcomputers.com , separate from http://www.swearingatcomputers.com , and that fits a lot of use cases.<br /><br />Not all of them, though. &nbsp;Sometimes you have a client who simply MUST have SSL for everything. &nbsp;Now you're in trouble. &nbsp;Here are your options:<br /><br />1) Set up your own load balancer on a separate, micro instance. &nbsp;ELB is nice, but if it can't do what you want, you gotta do it the old fashioned way.<br /><br />2) Set up a simple Apache instance with the certs installed, and "redirect permanent" to www.swearingatcomputers.com, which is your ELB CNAME.<br /><br />3) Cry about it.<br /><br />I tried option 3, but it didn't help. &nbsp;Which of the other two options would you take?
</div>


<p></p>
]]></content>
  </entry>
  
</feed>
